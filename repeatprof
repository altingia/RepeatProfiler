#!/bin/bash
commands=$@
BASE="refbase_"
num_commands=`echo $commands | wc -w ` #gets the number  of commands

if ((num_commands == 0 )) # if no commands entered, show this
 then

echo "RepeatProfiler v 0.94 -prerelease- x fast x as x the hedgehog x"
echo "use -h flag for help using this tool"
echo "____ ____ ___  ____ ____ ___    ___  ____ ____ ____ _ _    ____ ____"
echo "|__/ |___ |__] |___ |__|  |     |__] |__/ |  | |___ | |    |___ |__/ "
echo "|  \ |___ |    |___ |  |  |     |    |  \ |__| |    | |___ |___ |  \ "

exit 1

fi

rm -f -r  *.out *.bam *fofn* Errors_README.log Single_summary.csv normalized_table.csv #images-RP Single_summary.csv #brew stuff
currentDate=`date`
currentDate=`tr ' :' '_' <<<"$currentDate"`
rm -f Errors_README.txt
echo "generating symlinks"

#brew link --overwrite >/dev/null 2>&1  #brew stuff
#mydir=`echo "$(brew --cellar repeatprof)/0.92/libexec"` #brew stuff
R_packages="default_rpackages"
#R_packages=`echo "$(brew --cellar repeatprof)/0.92/R_packages"` #brew stuff
#images=`echo "$(brew --cellar repeatprof)/0.92/images-RP"`  #brew stuff
#Rscript=`echo "$(brew --prefix R)/bin/Rscript"`  #brew stuff
mydir=`pwd` #comment when running it for brew
mydir="${mydir}/scripts/" #comment when running it for brew
Rscript="Rscript" #comment when running it for brew




##### this block checks for correct command structure and does error handling 

if  [[ $1 == "profile" ]] || [[ $1 == "corr" ]] ||  [[ $1  ==  "clean" ]] || [[ $1 ==  "-h" ]] || [[ $1 == "pre-corr" ]]; then  # check if the 2nd parameter is any of these. If not, terminate the program and tell the user.
echo "" > /dev/null

else
echo "Incorrect command structure -- invalid first argument after 'repeatprof'. Use 'repeatprof -h' to view valid commands or refer to the manual."
exit 1

fi


currentdir=`pwd`



if [ "$1" == "profile" ]; then  # check if the second parameter is profile, If yes then preform profiling stuff

#cp -r $images $currentdir #brew stuff images-RP
if  [[ $2 == "-u" ]] ||  [[ $2  ==  "-p" ]]; then # check if the user input -u or -p if not give him an error as it is a madantory command
echo "" > /dev/null

else
echo "second parameter should be -u or -p"
exit 1

fi


if (( num_commands < 4 )) #If commands are less than 4 (which is number of the 4 madantory flags for profile)
 then
echo "Missing madantory arguments for 'profile' command. Use 'repeatprof -h' to view list of mandatory arguments for 'profile' or refer to the manual."
exit 1

fi

commands=$@ #this gets all parameters of a command. It is a shell thing
array=(${commands})   # this is able to put a string separated by spaces in an array, so this basically put the parameters in array
index=0 # this keep track of the index while looping through array by element.

for t in "${array[@]}"  #for each element in the array
do

if [[ $t  ==  "-o" ]]; then # this if statement says if the flag in the array is -o  (stands for output folder directory ) then check for the next element in the array
	((index ++))
	the_path=${array[index]}

	    if [[ -d $the_path ]]; then
		 echo "the output will be directed to  $the_path "

		else
		   echo "Specified output directory path invalid. Specify a valid path (check for blanks in directory names), or omit the -o flag and output will be written to current directory."
		   exit 0
		fi
		
    fi
		((index ++))
done


for t in "${array[@]}"  #for each element in the array
do

rmdup="FALSE"
#checking for flag to remove duplicates or not 
if [[ $t  ==  "-rmdup" ]]; then # this if statement says if the flag in the array is -o  (stands for output folder directory ) then check for the next element in the array
	rmdup="TRUE"


fi
done



# continues checking command structure for optional flags as the example explained above ^

verticalplots="false"	
for t in "${array[@]}"  #for each element in the array
do

if [[ $t  ==  "-vertical" ]]; then # this if statement says if the flag in the array is -o  (stands for output folder directory ) then check for the next element in the array
        echo "vertical color gradient profiles will be produced"
	    verticalplots="true"
    fi
done

#
array=(${commands})
index=0
reads=$4

for p in "${array[@]}"
do

if [[ $p  ==  "-corr" ]]; then
	((index ++))

##### end command structure checks and error handling




##### this block does an initial check to detect read data, does error handling, and makes relevant files of file names for downstream loops etc.

if [ $2 = "-p" ]; then #if user specified paired data then look for this 

ls ${4}/*_R1.fastq ${4}/*_R1.gz ${4}/*_R1.fq ${4}/*_R1.fq.gz  ${4}/*_1.fq ${4}/*_1.fq.gz ${4}/*_1.gz ${4}/*_1.fastq > fofn1.txt 2>/dev/null
ls ${4}/*_R2.fastq ${4}/*_R2.gz ${4}/*_R2.fq ${4}/*_R2.fq.gz  ${4}/*_2.fq.gz  ${4}/*_2.fq ${4}/*_2.gz ${4}/*_2.fastq > fofn2.txt 2>/dev/null

fi

if [ $2 = "-u" ]; then
#if user specified unpaired data then look for that. We make 2 fofn for unpaired data here because downstream code was built on paired data, but in the end the second fofn for unpaired data will be ignored
if [[ -f $reads ]]; then
if [[ $reads == *.fq ]] || [[ $reads == *.fastq ]] || [[ $reads == *.gz ]]; then 
ls $reads > fofn1.txt
ls $reads > fofn2.txt 

else 

echo "The path to the unpaired reads file(s) is incorrect, or the file(s) format is unsupported"
echo "Make sure the path is correct (note that spaces in directory names may cause errors). Make sure read files have '.fastq' or '.fq' extensions. Compressed (i.e., '.gz') formats also accepted (e.g., 'fastq.gz')."
exit 1
fi 

else 
  ls ${reads}/*.fastq ${reads}/*.gz ${reads}/*.fq     > fofn1.txt 2>/dev/null
  ls ${reads}/*.fastq ${reads}/*.gz ${reads}/*.fq    > fofn2.txt 2>/dev/null   #Even though this code is for -u (unpaired data) we still make two fofns that are identical. We do this just as a work around for downstream code, but one of the two will be ignored in the end.

fi 

fi

#checks if the lines of the fofn for pair 1 is equal to lines fofn of pair 2 if not then give an error because that mean user has missing data if paired  
echo "checking reads"
reads1_check=`cat fofn1.txt | wc -l` 
echo $reads1_check
reads2_check=`cat fofn2.txt | wc -l `


if [[ $reads1_check == 0 && $reads2_check == 0 ]];then #if both are empty then there was no reads of correct format to begin with 
echo ""
echo "The path to the paired reads file(s) is incorrect, or the file(s) format is not supported"| tee -a Errors_README.log
echo "Make sure the path is correct (note that spaces in directory names may cause errors). Make sure read files have '.fastq' or '.fq' extensions. Compressed (i.e., '.gz') formats also accepted (e.g., 'fastq.gz')."| tee -a Errors_README.log
exit 1

fi

if [ "$reads1_check" != "$reads2_check" ]; then

echo "There is a pair of reads missing. Ensure all reads read pairs are present in input directory"| tee -a Errors_README.log
exit 1

fi


#ls ${DIR}/*.fa > fofn3.txt
#counts number of lines in fofn1.txt and stores variable as MAX
MAX=`wc -l < fofn1.txt`

##### end initial check and error handling for read data 


	

##### checks input file for -corr flag, error handling

	user_prov=${array[index]}
	    if [[ -f $user_prov ]]; then
		rm -f user_groups.txt
        lines=`cat $user_prov | wc -l`
		lines=`echo $[$lines-1]`
	    if [[ $lines -ne $MAX ]]; then
           echo "Read files listed in user_groups.txt don't match the read files in path to reads you provided for this run. Ensure that user_groups is correctly formatted, and the path to reads is correct."
		   echo "The user_groups.txt file format does not match read format selected for this run (i.e., -p or -u) If user_groups.txt was formatted for unpaired data, -u must be specified for the run. If formatted for paired data, -p must be specified. See help menu or user manual."
		   exit 1 
         fi		
        
		currentdir=`pwd`

		 cp $user_prov  $currentdir
		 
		elif [[ -f user_groups.txt ]]; then
        lines=`cat user_groups.txt | wc -l`
		lines=`echo $[$lines-1]`
		echo "$lines"
		infolder=true
	    if [[ $lines -ne $MAX ]]; then
           echo "Read files listed in user_groups.txt don't match the read files in path to reads you provided for this run. Ensure that user_groups is correctly formatted, and the path to reads is correct."
		   echo "The user_groups.txt file format does not match read format selected for this run (i.e., -p or -u) If user_groups.txt was formatted for unpaired data, -u must be specified for the run. If formatted for paired data, -p must be specified. See help menu or user manual."
		   exit 1 
         fi		
	     echo '' > /dev/null

		else

		   echo "File 'user_groups.txt' not found. -corr option requires user-defined groups to be specified in user_groups.txt. This file is not present in the current directory, and no alternative path was provided. See repeatprof -h or user manual for help"
		   echo "Correlation analysis skipped"
		   exit 0

		fi
    
    fi
	((index ++))
done

##### end -corr input check and, error handling. Also end of checks for optional flags (and handling errors) that was supplied with profile command




The_folder="$currentDate-RP"
mkdir $The_folder # this creates the main output folder




BASE="refbase_" #this is just for the naming of the refrence index made by bowtie2-build, so it can be detected later when aligning using bowtie2
commands=$@


#refs_full_path=`readlink -f $3`

before_pwd=`pwd`

if [[ -f $user_prov ]]; then
	
	cp  $user_prov $The_folder

elif [ "$infolder" == "true" ]; then 

cp user_groups.txt $The_folder

fi

cd $The_folder
exec > >(tee -i logfile.log)

if [[ -f $3 ]]; then 

refs_full_path=$3

else

refs_full_path=`echo "${before_pwd}/$3"`

fi 

The_folder=${The_folder}_output

mkdir $The_folder

##### detects input reference file(s), prepares them for the run using fasta_splitter script, error handling 

if [[ -d $refs_full_path ]]; then # checking if 3rd parameter (refrence path) for profile is directory or a file
#if it is a directory then sum up all the .fa files and put them int o one and send them to fasta splitter to prepare them as single fasta sequences for analysis
	path_refs=`cat $refs_full_path/*.fa > all_refs.fa`


bash $mydir/fasta_splitter.sh $refs_full_path


retval=$? #check if any error occured by getting the exit code

if [ $retval -eq 2 ]; then #if an error occured and the exit code isn't 0 then exit. The error message will be printed from map_mileup not here
exit 1

elif [ $retval -ne 0 ]; then #if an error occured and the exit code isnt 0  then exit. The error message will be printed from map_mileup not here
	echo "Something is wrong with the file containing reference sequences -- check that it is in fasta format and the last line ends in a carriage return"
exit 1

fi


	refs=references_used #this is where bowtie will look for refrence sequence ot align. It is a sub directory

elif [[ -f $refs_full_path ]]; then # if the reference entered as a file  then just send it to fasta splitter in case it is multi sequence fasta
	rm -f -r references_used

	bash $mydir/fasta_splitter.sh $refs_full_path #split comment


retval=$? #check if any error occured by getting the exit code

if [ $retval -eq 2 ]; then #if an error occured and the exit code isnt 0  then exit. The error message will be printed from map_mileup not here
exit 1

elif [ $retval -ne 0 ]; then #if an error occured and the exit code isnt 0  then exit. The error message will be printed from map_mileup not here
	echo "Something is wrong with the file containing reference sequences -- check that it is in fasta format and the last line ends in a carriage return"
exit 1

fi

refs=references_used

else
    echo "The path to file containing the reference sequence(s)is not valid"
    exit 1

fi


#this is just to clear out the clutter one-time use intermidiate output 
rm -f -r Errors.log  2> /dev/null
rm *bam *bt2  2> /dev/null
rm -f -r map_depth_allrefs  2> /dev/null

##### end detection, processing and error handling of input reference sequences




mkdir map_depth_allrefs #this creates map_depth_allrefs where it store  a table of postion of reference and the coverage depth (the folder will be used later by $Rscripts)

Normalized=false #this is equal 1 always unless the user chooses to normalize 

rm -f *out  2> /dev/null




##### This block is for normalization analysis (e.g., -singlecopy flag), detects mapping settings, runs external script, error handling


#cat $refs/*.fa > all_References.fa #the folder where fasta spliter stores all the .fa file after splitting them. This line just gets a list of these references with their paths



# Work in progress




p=8 #this is the deafult threads

commands=$@
array=(${commands})
index=0
#we did this before we will check if -t was entered in optional arguments
for th in "${array[@]}"
do

if [[ $th  ==  "-t" ]]; then
	((index ++))
	p=${array[index]}
	    re='^[0-9]+$'

	if ! [[ $p =~ $re ]] ; then #make sure the user entered a number for threads not some nonsense words
	p=4
	fi
fi
		((index ++))

done
echo "Threads used: $p" #prints to the user what threads is being used


#the following is the same checking for optional flag but this time it is for bowtie settings
a="--very-sensitive-local"
commands=$@
array=(${commands})

for i in "${array[@]}"
do

if [[ $i  ==  "--very-fast" ]] || [[ $i  ==  "--local" ]] || [[ $i  ==  "--fast" ]] || [[ $i  ==  "--sensitive" ]] || [[ $i  == "--very-sensitive" ]] || [[ $i  ==  "--very-fast-local" ]] || [[ $i  ==  "--fast-local" ]] || [[ $i  ==  "--sensitive-local" ]] || [[ $i  ==  "--very-sensitive-local" ]]; then
		a=$i
    fi
done


if [[ $@  ==  *"-D"* ]]; then
commands=$@
a=`echo "$commands" | awk '{for (I=1;I<=NF;I++) if ($I == "-D") {print $I " " $(I+1) " " $(I+2) " " $(I+3)" " $(I+4) " " $(I+5) " " $(I+6) " " $(I+7) " " $(I+8) " " $(I+9) };}' `

fi

echo "Bowtie2 alignment settings: $a"
echo $4
line="All_references"




#used to be were mapping is done in the past. 

retval=$? #check if any error occured by getting the exit code

if [ $retval -ne 0 ]; then #if an error occured and the exit code isnt 0  then exit. The error message will be printed from map_mileup not here
exit 1
fi

echo "yes"
















#check if singlecopy gene present if singlecopy option selected
for i in "${array[@]}"
do

if [[ $i == "-singlecopy" ]]; then

grep "_singlecopy" all_References.fa | sed 's/^.//'  > fofnsingle.txt

echo ""

fofnsinglecheck=`cat fofnsingle.txt | wc -l`

if [ $fofnsinglecheck == 0 ];then #if both are empty then there was no reads of correct format to begin with
  echo "PROBLEM !"
  echo "No singlecopy genes sequences detected in the reference sequence file you provided. Make sure your single copy reference names in the Fasta file end with '_singlecopy' "
  echo "more info can be found on the github page, or try repeatprof -h "
  exit 1
fi

fi

done








bash $mydir/readme_gen.sh #this starts generating the readme. which will be populated later with the index to read conversions



##preps references for read mapping in bowtie2
bowtie2-build all_References.fa $BASE 

##calls map_reads.sh which runs bowtie aligning and uses the indexes we built and also run samtools mpileup
bash $mydir/map_reads.sh $line $4 $2 $p $a $rmdup


retval=$? 

if [ $retval -ne 0 ]; then #if an error occured and the exit code isnt 0  then exit. The error message will be printed from singlecopy.sh not here
exit 1

fi

echo "mapped reads"



















for i in "${array[@]}"
do

if [[ $i == "-singlecopy" ]]; then
  

a="--very-sensitive-local"
commands=$@
array=(${commands})

for i in "${array[@]}"
do

if [[ $i  ==  "--very-fast" ]] || [[ $i  ==  "--local" ]] || [[ $i  ==  "--fast" ]] || [[ $i  ==  "--sensitive" ]] || [[ $i  == "--very-sensitive" ]] || [[ $i  ==  "--very-fast-local" ]] || [[ $i  ==  "--fast-local" ]] || [[ $i  ==  "--sensitive-local" ]] || [[ $i  ==  "--very-sensitive-local" ]]; then
		a=$i
    
	fi

if [[ $@  ==  *"-D"* ]]; then
commands=$@
a=`echo "$commands" | awk '{for (I=1;I<=NF;I++) if ($I == "-D") {print $I " " $(I+1) " " $(I+2) " " $(I+3)" " $(I+4) " " $(I+5) " " $(I+6) " " $(I+7) " " $(I+8) " " $(I+9) };}' `

fi 
done

echo ""
	echo "The alignment setting for single copy calculations is $a"



#Runs external script for normalization analysis 
bash $mydir/singlecopy.sh $mydir $4 $2 "2" $a $rmdup $refs_full_path





retval=$? 

if [ $retval -ne 0 ]; then #if an error occured and the exit code isnt 0  then exit. The error message will be printed from singlecopy.sh not here
exit 1

fi




Normalized=true
readnumbers=`cat fofnsingle.txt | wc -l`
echo "Normalization values calculated:"
rm -f -r plots_single_copy
mkdir plots_single_copy


$Rscript $mydir/single_copy_calculator.R $readnumbers

$Rscript $mydir/mk_profiles_single.R plots_single_copy $R_packages $Normalized

mv single_cvs plots_single_copy

mv plots_single_copy $The_folder
pwd
echo ""

echo "Normalization calcaulations ended "
echo ""

##### 

fi
grep  ">" all_References.fa | grep -v "_singlecopy" | sed 's/^.//'  > fofnrefs.txt

done 
#exit 1 # STOP HERE
##### end of normalization (-singlecopy) block 



##### more error handling of input references and preparation for read mapping

#ls $refs/*.fa > fofnrefs.txt  2> /dev/null #the folder where fasta spliter stores all the .fa file after splitting them. This line just gets a list of these references with their paths

fofncheck=`cat fofnrefs.txt | wc -l` 

if [[ $fofncheck == 0 ]];then #if both are empty then there was no reads of correct format to begin with 

echo "Only _singlecopy reference sequences detected in fasta file containing reference sequences." 
echo "The program expects repeat references (lacking _singlecopy in the sequence header) to also be present"

exit 1
fi



echo "Reference	Sample_index	Read1	Read2	Total_reads	percent_mapped" > The_summary.txt #preparing the summary table




##### end above block




##### detects settings for read mapping, maps reads by calling script that runs bowtie2, loops through all references, begins organizing output

while read line  # for each line  in the fofnrefs.txt we will loop through it and carry the following analysis
do


#echo $line | cat -v 
#exit 1
line=$(echo $line | tr -cd "[:print:]\n")

echo $line

echo $line
echo $refs_full_path

awk '/^>/ { if(NR>1) print "";  printf("%s\n",$0); next; } { printf("%s",$0);}  END {printf("\n");}'  all_References.fa | grep -A 1 $line > temp.fa
temp=`awk '/^>/ { if(NR>1) print "";  printf("%s\n",$0); next; } { printf("%s",$0);}  END {printf("\n");}'  all_References.fa | grep -A 1 $line | tail -n1`
#echo $temp

ref_char_count=`echo $temp | wc -c` #this gets the reference sequence length

echo $ref_char_count

name_ref=`tr ' 	\\<.,:#"/\|?*' '_' <<<"$line"` # this awk command is to get the reference name from the path of references stored in fofnrefs.txt we did earlier
echo $name_ref
											   # this command separates on / and get the last word which is the reference name

if [[ $ref_char_count == 0 ]]; then			   # if the  the length of the specfic reference is 0 then just skip it.
											   # it skips it by just printing the below message and nothing else will be executed because everything done is in the else statemen of this
echo ""
echo "your $name_ref is an empty sequence or not in the correct format. It will be ignored in this run. " | tee -a Errors_README.log
echo ""

else
The_ref_size=$ref_char_count #same as above re_char_count




  #  bowtie2-build $line $BASE > /dev/null 2> /dev/null # this build index for the current reference
    echo "The reference sequence currently under analysis:"
    echo "$line"
    echo ""

#bash index_refs.sh
name_ref=`tr ' 	\\<.,:#"/\|?*' '_' <<<"$line"`  #same as above just to make sure

Ref_name=$name_ref #assigning it to another variable

stringe="$Ref_name"
stringee="_output"
the_output="$stringe$stringee" #i sum up both variables to create the suboutput folder for that reference REFname_ouput. The one you see in the big folder
rm -f -r $the_output
mkdir $the_output


echo "$the_output" >>fofn_Theoutputs.txt #this appends the fofn_the outputs with the current name (it gets created by the first append at the first reference rest is appennding)
										 # keeping track of the folder names will help in the future when assigining stuff to each folder

##### end read mapping block




numPairpile=1 #this will keep count of the index reads



##### extracts sorted bam for each reference from master bam 

refname_toextract="$line"

M=1
while read mastername
do 
F=`printf "%03d\n" $M` #this puts the number in format 001 for example

samtools index $mastername

echo "$refname_toextract" | cat -v

echo $line

samtools view  $mastername $line -o ${F}_sorted.bam  #we extract our aligned reference from the master bam for this read index 
#doing calculations used in the run_summary table
READ1=`sed -n "$M p"  fofn1.txt`
READ2=`sed -n "$M p"  fofn2.txt`
Read1name=$(awk -F "/" '{print $NF}' <<< $READ1) #seprates the read name on / and gets the last thing sperated
Read2name=$(awk -F "/" '{print $NF}' <<< $READ2)
allreads=`sed -n "$M p"  reads_lengths.txt`
mappedreads=`samtools view -F 0x4 ${F}_sorted.bam | cut -f 1 | sort | uniq | wc -l`

aligned=`echo "scale=4 ; $mappedreads / $allreads" | bc`

echo "mappedreads: $mappedreads"
echo "aligned : $aligned"

echo "${refname_toextract}	S${F}	$Read1name	$Read2name	$allreads	$aligned" >> The_summary.txt


	((M ++))

done < master_bams.txt 

##### end extraction of bam files from master bam




##### this block uses mpileup to to gather variant and depth information from bam files, summarizes mipleup output with an external script and write output

N=1 #resets counter for new loop
MAX=`wc -l < fofn1.txt`
#Loops through all .bam files and does mpileup command.
while ((N<=MAX))
	#if ((count<=max))
do
	F=`printf "%03d\n" $N`
	echo "calculating read depth at each position" #put a comment

## runs samtools mpileup
	samtools faidx temp.fa
	samtools mpileup -f temp.fa -q 0 -Q 13 -d 0 -A -o ${F}_pileup.out -O ${F}_sorted.bam 

	((N ++))
done #< RefList2.txt
echo "save me"
#exit 1
#exit 1

ls *.out > fofn_pileup.txt
ls *.bam > fofn_bam.txt

#name_ref

echo "name_poly" > multi_poly_names.txt #this creates a text file called multi_poly_names.txt this is used to keep track of the reads that we are drwaing the graphs for
										# LIKE for example Refrencename_001  001 reference to the read the index we talked about before
rm -f -r multi_poly
mkdir multi_poly
rm -f temp_cvs
mkdir temp_cvs #this store the current postion vs coverage depth of the current reference (this is used in r script)
while read pairpile # for each pair pile this means for each pileup output from the map_mpileup
do

F=`printf "%03d\n" $numPairpile` #this convert 1 to 001 for example this allow naming to be in order

pile_counted_name="${Ref_name}_${F}" #this is the pileup counted name

echo $pile_counted_name >> multi_poly_names.txt #now populate the  multi_poly_names


## calls python script to summarize mpileup info

echo $The_ref_size
python $mydir/pileup_basecount.py $pairpile $pile_counted_name $The_ref_size # this script simplifies the output from the mpileup commmand above and makes a table of  file and count depth read depth and variant information for each sample

cp "$pile_counted_name.csv" map_depth_allrefs # cp the selected .csv produced by the python script
mv "$pile_counted_name.csv" temp_cvs #this moves it to temp_cvs  also. both steps are needed to be done because all_depths_cvs runs at the end for the all references statistcs   while temp_cvs just for this reference combined graphs and scaling

output=$Ref_name

stringpile2="$F"
stringpile3="_"
output="$output$stringpile3$stringpile2" #this just combines the output with its number to create the sub folder of the reference folder you see REF_001 for example where it contains the graphs

##### end mpileup and variant summary







########################################### begin plotting data for profile visualization ##########################################


##### makes variant plots for each sample using output from the python script above that summarizes variant and depth information

echo "$output" >> fofn_folders.txt #adds the name to the fofn_folders.txt

## calls R script that makes depth profiles that summarize variants


$Rscript $mydir/var_plots.R $output $R_packages 
rm -f -r $output
mkdir $output

mv  *.pdf  depth_counts.txt  $output
#mv $output $the_output  # we are not moving now we move in next pile up loop

((numPairpile ++))
done < fofn_pileup.txt #after finishing all the mapping and creating the csv files now we can start plotting graphs by scaling among all data
#loops through all samples and makes indiviual color ramp graphs and saves them in a folder
while read folder_names #for each line in folder name where we stored the folder name like REF_001
do

echo $folder_names #say it


## calls R script that makes color gradient profiles from read depth information
$Rscript $mydir/mk_profiles.R $folder_names $R_packages $Normalized $verticalplots

mv $folder_names $the_output
done < fofn_folders.txt

rm -f *.pdf
##This makes the combined colorful plots with plots from all samples for a given reference 
$Rscript $mydir/mk_profiles_ref.R $R_packages $Normalized


##This makes the combined variant plots with plots from all samples for a given reference 
$Rscript $mydir/multi_var_plots.R $R_packages

rm -f Rplots.pdf
#move R scripts to their relevant output folder
mv *scaled_profiles* $the_output
mv *.pdf $the_output
rm -f *.phy

##### end plotting of variant and color depth profiles



##### calls script that converts variant information for each profile into an alignment of molecular morphological characters for phylogenetic analysis
$Rscript $mydir/encode_var.R  > Closely_related_reads_analysis.txt

mv *.phy $the_output

#mv *variation_analysis* $the_output
rm -f Closely_related_reads_analysis.txt #we dont need this anymore

###### end variant summary in alignments




############## MAY REMOVE ######   It was used for validating all_corr analysis 

 # if [[ $@  ==  *"-corr"* ]]; then #if the user enter -corr check for user_groups.txt is in the same directory then run it and see if there is errors and run it
#  rm -f  R_correlation_errors.txt
# 
#  if [[ !(-f user_groups.txt) ]]; then
#  echo "user_groups.txt was not found. Matrix of pairwise correlation values will be generated, but no analysis of groups will be conducted." > R_correlation_errors.txt
#  fi
# 
# 
# ## if no errors, do prep for correlation analysis by calling external script that preps corr analysis (the output of this script isn't saved in the end, the final corr ouptut is generated by all_corr.R called below)
#  $Rscript $mydir/corr_test.R $the_output $R_packages $Normalized  2> /dev/null
# 
# 
#  if [ -f R_correlation_errors.txt ]; then
# 
#  mv R_correlation_errors.txt $the_output
#  fi
# 

#mv multi_poly $the_output    uncomment when testing
#mv multi_poly_names.txt $the_output

##### end initial prep for correlation analysis (that should may be removed, see ln 690)



##### This block moves output for a given reference to the relevant folders.

fi # end of pile up

mv temp_cvs $the_output #for testing
#mv multi_poly $the_output #for testing
#mv multi_poly_names.txt $the_output #for testing
rm -f -r multi_poly_names.txt multi_poly
mv $the_output $The_folder
rm -f folder_names.txt

rm -f *bt2
rm -f -r temp_cvs
rm -f fofn_folders.txt

 #this an fi for error handling dont mess with it. this is the end of the reference

done < fofnrefs.txt #keep looping until all references inputed undergone the analysis


rm -f Run_summary.csv
$Rscript $mydir/depth_analyser.R $Normalized #run the depth analyzer which produces the final summary table

if [[ -f Single_summary.csv ]]; then 
cat Run_summary.csv Single_summary.csv  > Run_summary2.csv
rm -f Run_summary.csv
mv Run_summary2.csv Run_summary.csv
fi 

Number=`wc -l < fofn_bam.txt`


rm -f -r scaled_profiles_allrefs
mkdir scaled_profiles_allrefs #this creats folder where the graphs which will be scaled using mk_profiles_all.R stored

echo "Thenumber: $Number"

##### end organization of ouptut




##### calls script to combine color profiles for all references and puts them on the same color scale of coverage depth, more output organization

$Rscript $mydir/mk_profiles_all.R $Number $R_packages $Normalized

mv  scaled_profiles_allrefs $The_folder
mv  *ReadMe*  $The_folder #move read me to the final folder
mv The_summary.txt $The_folder
rm -f The_summary.txt ref_temp.txt bowtie.log  *db.2*

##### end combined color profiles and output organization




##### More prep for correlation analysis, calls external script to do correlation analysis, writes Readmes for output folders, organizes output

if [[ $@  ==  *"-corr"* ]]; then #if the user enter -corr check for user_groups.txt is in the same directory then run it and see if there is errors and run it

rm -f  R_all_correlation_errors.txt

if [[ !(-f user_groups.txt) ]]; then

echo "user_groups.txt was not found -- full correlation analysis skipped " > R_all_correlation_errors.txt

else
rm -f -r correlation_analysis

mkdir correlation_analysis
mkdir correlation_analysis/correlation_data
mkdir correlation_analysis/correlation_histograms
mkdir correlation_analysis/correlation_boxplots_by_group
mkdir correlation_analysis/correlation_boxplots_by_reference

rm -f *_boxplot.pdf*
rm -f correlation_summary.csv 


##calls script for overall correlation analysis
$Rscript $mydir/all_corr.R $R_packages $Normalized

#these echo statements make the ReadMe text file for correlation analysis
echo "*****correlation analysis*****"  > correlation_README.txt  
echo "" >> correlation_README.txt
echo "" >> correlation_README.txt
echo "Four output folders are included in Correlation analysis." >> correlation_README.txt
echo "">> correlation_README.txt
echo "First folder: correlation_boxplots_by_group">> correlation_README.txt
echo " This folder contains boxplots for each group defined in user_groups.txt. The boxplots combine correlation values across all repeat references used in the run. Each group has its own plot.">> correlation_README.txt
echo "">> correlation_README.txt
echo "Second folder: correlation_boxplots_by_reference">> correlation_README.txt
echo " This folder contains boxplots that show correlation of profile shape within and between user-defined groups for individual repeat references in the run.">> correlation_README.txt
echo "">> correlation_README.txt
echo "Third folder: correlation_data">> correlation_README.txt
echo " This folder contains correlation matrices for each reference. The matrices shows all the correlation values among all samples for a reference. Each refrence has its own matrix.">> correlation_README.txt
echo "">> correlation_README.txt
echo "Fourth folder: correlation_histograms">> correlation_README.txt
echo " This folder contains histograms of within and between-group correlation values for each reference.">> correlation_README.txt
echo "">> correlation_README.txt
echo "Last file: correlation_summary.csv">> correlation_README.txt
echo " This table contains average values of within and between each group correlation value for each reference. It summarizes information for all correlation values calculated in the run">> correlation_README.txt

mv correlation_README.txt correlation_analysis/
#
mv  correlation_analysis $The_folder
fi

if [ -f R_all_correlation_errors.txt ]; then
mv R_all_correlation_errors.txt $The_folder
fi

fi

mv map_depth_allrefs $The_folder
mv index_conv.txt $The_folder #for testing

mv Run_summary.csv Errors_README.log base_coverage_summary.csv $The_folder 2> /dev/null
rm -f  *Rplots* Single_summary.csv

if [[ -f normalized_table.csv ]]; then
mv  normalized_table.csv $The_folder

fi 

##### end correlation analysis and organization of output




rm -f  *fofn* *.out  all_refs.fa *.bam
#rm -f -r images-RP  #brew stuff
rm -f -r multi_poly multi_poly_names.txt index_conv.txt #comment when testing




##### checks for -k which says whether to keep bam file in output or not, final code of standard analysis
commands=$@
array=(${commands})
index=0

for k in "${array[@]}"
do

if [[ $k  ==  "-k" ]]; then
echo "transfering"
		mv master_bam $The_folder
fi
		((index ++))
done

rm -f -r master_bam


mv singlecopy_warnings.txt $The_folder 2> /dev/null

mkdir temp 
mv ${The_folder}/index_conv.txt ${The_folder}/The_summary.txt temp
mv *.txt *.fa *.fai temp
#design of the cow was borrowed from the famous cowsay package

echo "________________________________"
echo "< The analysis has been completed! >"
echo "--------------------------------"
if [[ -d $the_path ]]; then
cd ..
The_folder="$currentDate-RP"

mv $The_folder $the_path
fi

fi

##### end of -k check and code for standard analysis code




##### Helps prepare the user_groups input file if pre-corr is used

if [ "$1" == "pre-corr" ]; then
reads=$3

if  [[ $2 == "-u" ]] ||  [[ $2  ==  "-p" ]] ||  [[ $2  ==  "-v" ]]; then
echo "" > /dev/null

else
echo "Incorrect command structure for 'pre-corr'. Refer to repeatprof -h or manual for help"
exit 1
fi

if [ $2 = "-p" ]; then

ls ${reads}/*_R1.fastq ${reads}/*_R1.gz ${reads}/*_R1.fq  ${reads}/*_R1.fastq.gz ${reads}/*_R1.fq.gz  ${reads}/*_1.fq ${reads}/*_1.fq.gz ${reads}/*_1.gz ${reads}/*_1.fastq ${reads}/*_1.fastq.gz > fofn1.txt 2>/dev/null
ls ${reads}/*_R2.fastq ${reads}/*_R2.gz ${reads}/*_R2.fastq.gz ${reads}/*_R2.fq ${reads}/*_R2.fq.gz  ${reads}/*_2.fq.gz  ${reads}/*_2.fq ${reads}/*_2.gz ${reads}/*_2.fastq ${reads}/*_2.fastq.gz 	 > fofn2.txt 2>/dev/null

reads1_check=`cat fofn1.txt | wc -l`
reads2_check=`cat fofn2.txt | wc -l `

fi

##### end pre-corr help




##### if user specified unpaired data then look for that. We use it double here because rest of the code was built on paired data, but dont worry it gets dealt with laterye

if [ $2 = "-u" ]; then

if [[ -f $reads ]]; then

if [[ $reads == *.fq ]] || [[ $reads == *.fastq ]] || [[ $reads == *.fq.gz ]] || [[ $reads == *.fastq.gz ]]; then 
ls $reads > fofn1.txt

ls $reads > fofn2.txt

else 

echo "The path to the unpaired reads file(s) is incorrect, or the file(s) is/are in a unsupported format"

echo "Make sure the path is correct (including checking for blanks). Make sure read files have '.fastq' or '.fq' extensions. Compressed (i.e., '.gz') formats also accepted (e.g., 'fastq.gz')."


fi 

else 
  ls ${reads}/*.fastq ${reads}/*.gz ${reads}/*.fq     > fofn1.txt 2>/dev/null
  ls ${reads}/*.fastq ${reads}/*.gz ${reads}/*.fq    > fofn2.txt 2>/dev/null

fi 

fi

if [[ $reads1_check == 0 && $reads2_check == 0 ]];then
echo ""
echo "The path to the paired reads file(s) is incorrect, or the file(s) is/are in a unsupported format"| tee -a Errors_README.log
echo "Make sure your read pairs  are in .fastq or .gz or .fq AND revise the path inputed"| tee -a Errors_README.log
exit 1

fi

if [ "$reads1_check" != "$reads2_check" ]; then
echo "There is one or more pair of reads missing. Ensure all reads read pairs are present in input directory"| tee -a Errors_README.log
exit 1

fi

##### end above block





##### -corr flag can be run as a module independent of a full run. This block takes the output of a previous run and does correlation analysis
$Rscript $mydir/user_groups_maker.R $2

echo ""

fi

if [ "$1" == "corr" ]; then

if [[ ! -f user_groups.txt ]]; then
echo "user_groups.txt not found in current directory."
echo "Refer to repeatprof -h or the user manual for help"
exit 1 

fi

if  [[ $2 == "-u" ]] ||  [[ $2  ==  "-p" ]]; then # check if the user inputed -u or -p if not give him an error as it is a madantory command
echo "" > /dev/null

else
echo "Second parameter should be -u or -p"
exit 1

fi

if [[ ! -d $3 ]]; then 
echo "Invalid path to the output folder.refer to repeatprof -h to check command structure"

fi

if [[ ! -d $4 ]]; then 
echo "Invalid path to the reads folder. Please refer to repeatprof -h to check command structure"

fi 

reads=$4

if [ $2 = "-p" ]; then
ls ${reads}/*_R1.fastq ${reads}/*_R1.gz ${reads}/*_R1.fq  ${reads}/*_R1.fastq.gz ${reads}/*_R1.fq.gz  ${reads}/*_1.fq ${reads}/*_1.fq.gz ${reads}/*_1.gz ${reads}/*_1.fastq ${reads}/*_1.fastq.gz > fofn1.txt 2>/dev/null
ls ${reads}/*_R2.fastq ${reads}/*_R2.gz ${reads}/*_R2.fastq.gz ${reads}/*_R2.fq ${reads}/*_R2.fq.gz  ${reads}/*_2.fq.gz  ${reads}/*_2.fq ${reads}/*_2.gz ${reads}/*_2.fastq ${reads}/*_2.fastq.gz 	 > fofn2.txt 2>/dev/null
reads1_check=`cat fofn1.txt | wc -l`
reads2_check=`cat fofn2.txt | wc -l `

fi

if [ $2 = "-u" ]; then

#if user specified unpaired data  then look for that. We make two fofn here for unpaired data because rest of the code was built on paired data, the second copy will be ignored in the end
if [[ -f $reads ]]; then

if [[ $reads == *.fq ]] || [[ $reads == *.fastq ]] || [[ $reads == *.fq.gz ]] || [[ $reads == *.fastq.gz ]]; then 
ls $reads > fofn1.txt
ls $reads > fofn2.txt

else 

echo "The path to the unpaired reads file(s) is incorrect, or the file(s) format is not supported"
echo "Make sure the path is correct (note that spaces in directory names can cause errors). Make sure read files have '.fastq' or '.fq' extensions. Compressed (i.e., '.gz') formats also accepted (e.g., 'fastq.gz')."

fi 

else 
  ls ${reads}/*.fastq ${reads}/*.gz ${reads}/*.fq     > fofn1.txt 2>/dev/null
  ls ${reads}/*.fastq ${reads}/*.gz ${reads}/*.fq    > fofn2.txt 2>/dev/null

fi 

reads1_check=`cat fofn1.txt | wc -l`
reads2_check=`cat fofn2.txt | wc -l `

fi


if [[ $reads1_check == 0 && $reads2_check == 0 ]];then
echo ""

echo "The path to the paired reads file(s) is incorrect, or the file(s) is/are in a unsupported format"| tee -a Errors_README.log
echo "Make sure your read pairs  are in .fastq or .gz or .fq, check that the path to the reads is correct"| tee -a Errors_README.log

exit 1

fi

if [ "$reads1_check" != "$reads2_check" ]; then

echo "There is a pair of reads missing. Ensure all reads read pairs are present in input directory"| tee -a Errors_README.log
exit 1

fi


 lines=`cat user_groups.txt | wc -l`
lines=`echo $[$lines-1]`
echo "$lines"
MAX=`wc -l < fofn1.txt`
current=`pwd`

if [[ $lines -ne $MAX ]]; then
           echo "Read files listed in user_groups.txt don't match the read files in path to reads you provided for this run. Ensure that user_groups is correctly formatted, and the path to reads is correct."
		   echo "The user_groups.txt file format does not match read format selected for this run (i.e., -p or -u) If user_groups.txt was formatted for unpaired data, -u must be specified for the run. If formatted for paired data, -p must be specified. See help menu or user manual."
		   exit 1 
 fi		

if [[ -d ${3}/map_depth_allrefs ]]; then
rm -f -r depth_all_cvs
cp  -r ${3}/map_depth_allrefs $current

else
   echo "The output folder structure has been altered. map_depth_allrefs is missing. corr analysis halted"
   exit 1

fi 

if [[ -f ${3}/index_conv.txt ]]; then
rm -f index_conv
cp ${3}/index_conv.txt $current

else
   echo "The output folder structure has been altered. map_depth_allrefs is missing. corr analysis halted"
   exit 1  
   
fi 

rm -f -r  correlation_analysis/
mkdir correlation_analysis
mkdir correlation_analysis/correlation_data
mkdir correlation_analysis/correlation_histograms
mkdir correlation_analysis/correlation_boxplots_by_group
mkdir correlation_analysis/correlation_boxplots_by_reference

## calls script to do modular corr
$Rscript $mydir/all_corr.R $R_packages 1

rm -f -r depth_all_cvs
rm -f index_conv

fi
#####end of modular corr




#####code for 'clean' command

if [ "$1" == "clean" ]; then
rm -f -r *bam *fofn* *.out* *multi_poly_names* correlation_analysis *_output* *_conv* *summary* *bt2* *ref_temp* *bowtie.log* *ReadMe* *_cvs* *_temp* *db.2* *Rplots* all_refs.fa references_used #images-RP #brew stuff
rm -f  -r R_all_correlation_errors.txt normalized_table.csv single_cvs Single_summary.csv
echo "remians of a broken run were cleaned successfuly "
fi

##### end 'clean' command




#####code for help menu
if [ "$1" == "-h" ]; then
echo ""
echo "Thank you for checking out RepeatProfiler."
echo "Have a look at our GitHub page (https://github.com/johnssproul/RepeatProfiler) for more info"
echo ""
echo "Usage:"
echo ""
echo "General command structure:"
echo "    repeatprof profile <'-p' for paired-end reads or '-u' for single-end> <filename (or path) of references>" 
echo "                       <path to reads folder> [opitonal flags]"
echo ""
echo "Example command: 'repeatprof profile -p Refs.fa /RepeatProfilerData/Test1'"
echo "    Explanation:"
echo "	'repeatprof' calls the program"
echo "	'profile' command to run primary analysis"
echo "	'-p' tells the program input reads are paired"
echo "	'Refs.fa' name of file with reference sequences (provide path if not in current directory"
echo "	'/RepeatProfilerData/Test1' path to folder with input reads"
echo ""
echo ""
echo "Commands:"
echo "    profile .............. Primary analysis command, see 'Example command' above for required arguments."
echo "    pre-corr ............. Auto-generates user_groups.txt base file for correlation analysis."
echo "    clean ................ Cleans up directory following a terminated/broken run"
echo ""
echo ""
echo "Optional flags:"
echo "    -h ................... Displays help menu."		
echo "    -t ................... Sets the number of threads. Default is 4."
echo "    -k ................... Use this flag to keep bam files in the final output folder."
echo "    -o <folder_path> ..... Directs output to specified folder. Default is current directory."
echo "    -corr ................ Runs a correlation analysis of profile shape among user-defined groups."
echo "  		     	      Requires user_groups.txt input file in current directory. see manual."
echo "    -corr <file_path> .... Used to run correlation analysis when user_groups.txt is not in" 
echo "			      current directory."
echo "    -vertical ............ Generates color-scaled profiles with a vertical color gradient." 
echo " 			      Default is a horizontal gradient."
echo "    -singlecopy .......... Normalizes read coverage of all samples relative to single-copy genes." 
echo "			      Add one or more single-copy sequences to reference sequence file and append" 
echo " 			      their FASTA header with '_singlecopy. see manual.'"
echo "    --<bowtie_command> ... Allows user to change Bowtie 2 mapping parameters. Valid arguments" 
echo " 			      include '--very-fast-local', --fast-local', '--sensitive-local', '--very-sensitive-local',"
echo "			      '--very-fast','--fast', '--sensitive', '--very-sensitive'. In addition to Bowtie 2 presets,"
echo "			      full bowtie command strings may be used. Default is '--very-sensitive-local."
echo ""
echo "Supported input formats:"
echo "    -Reference sequences should be in FASTA format. Valid extensions include: '.fa' .'fasta' '.txt' "
echo ""
echo "    -Input reads should be in FASTQ format (zipped, or not)." 
echo "         -Valid extensions include: '.fastq', '.fq', '.fastq.gz', and '.fq.gz'"
echo "         -For paired reads the last string before the file extension should be ‘_1’ and ‘_2’" 
echo "              for reads 1 and 2 respectively (alternatively ‘_R1’ and ‘_R2’ also supported)"
echo "         -An example of a valid paired read file names is: ‘SampleName_1.fastq.gz’ (read 1)" 
echo "                                                           ‘SampleName_1.fastq.gz’ (read 2)"
echo ""
echo "*Check our github page https://github.com/johnssproul/RepeatProfiler for more info"

fi

if [ "$1" == "-cow" ]; then

echo "________________________________"
echo "< WOW what a great pipeline !!!! >"
echo "--------------------------------"
echo "       \   ^__^"
echo "        \  (oo)\_______         "
echo "           (__)\       )\/\  "
echo "               ||----w |    "
echo "               ||     ||    "
fi
##### end help menu
